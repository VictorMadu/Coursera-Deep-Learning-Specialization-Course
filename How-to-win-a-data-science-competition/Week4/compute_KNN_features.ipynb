{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "compute_KNN_features.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VictorMadu/Coursera-Deep-Learning-Specialization-Course/blob/master/How-to-win-a-data-science-competition/Week4/compute_KNN_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt4tFadKYwck",
        "colab_type": "text"
      },
      "source": [
        "Version 1.1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQMNoNjTYwcn",
        "colab_type": "text"
      },
      "source": [
        "# The task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNWJijwBYwco",
        "colab_type": "text"
      },
      "source": [
        "In this assignment you will need to implement features, based on nearest neighbours. \n",
        "\n",
        "KNN classifier (regressor) is a very powerful model, when the features are homogeneous and it is a very common practice to use KNN as first level model. In this homework we will extend KNN model and compute more features, based on nearest neighbors and their distances. \n",
        "\n",
        "You will need to implement a number of features, that were one of the key features, that leaded the instructors to prizes in [Otto](https://www.kaggle.com/c/otto-group-product-classification-challenge) and [Springleaf](https://www.kaggle.com/c/springleaf-marketing-response) competitions. Of course, the list of features you will need to implement can be extended, in fact in competitions the list was at least 3 times larger. So when solving a real competition do not hesitate to make up your own features.   \n",
        "\n",
        "You can optionally implement multicore feature computation. Nearest neighbours are hard to compute so it is preferable to have a parallel version of the algorithm. In fact, it is really a cool skill to know how to use `multiprocessing`, `joblib` and etc. In this homework you will have a chance to see the benefits of parallel algorithm. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5plw4eSYwcp",
        "colab_type": "text"
      },
      "source": [
        "# Check your versions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkA_Pr7EYwcr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Some functions we use here are not present in old versions of the libraries, so make sure you have up-to-date software. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9bKiqfDbA9b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "85a7466b-3b85-4e9f-d4c0-1706b98cd306"
      },
      "source": [
        "!pip install numpy==1.13.1\n",
        "!pip install scipy==0.19.1\n",
        "!pip install scikit-learn==0.19.0\n",
        "!pip install pandas==0.20.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/e2/57c1a6af4ff0ac095dd68b12bf07771813dbf401faf1b97f5fc0cb963647/numpy-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (17.0MB)\n",
            "\u001b[K     |████████████████████████████████| 17.0MB 1.3MB/s \n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tifffile 2020.7.24 has requirement numpy>=1.15.1, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement scipy==1.4.1, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.10.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.10.1 has requirement scipy>=1.0.1, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pywavelets 1.1.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 0.14.1 has requirement numpy>=1.14, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas 1.0.5 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: numba 0.48.0 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: librosa 0.6.3 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: featuretools 0.4.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement scipy>=1.1.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: blis 0.4.1 has requirement numpy>=1.15.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.0.1.post1 has requirement numpy>=1.16, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "Successfully installed numpy-1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy==0.19.1 in /usr/local/lib/python3.6/dist-packages (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==0.19.1) (1.13.1)\n",
            "Collecting scikit-learn==0.19.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/b3/209652a5d60ce4a2a8a35ad893d7565bbb0f87ce043264ba5c9e7de304cd/scikit_learn-0.19.0-cp36-cp36m-manylinux1_x86_64.whl (12.4MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4MB 327kB/s \n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: yellowbrick 0.9.1 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: librosa 0.6.3 has requirement scikit-learn!=0.19.0,>=0.14.0, but you'll have scikit-learn 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: librosa 0.6.3 has requirement scipy>=1.0.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imbalanced-learn 0.4.3 has requirement scikit-learn>=0.20, but you'll have scikit-learn 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 has requirement scikit-learn>=0.19.1, but you'll have scikit-learn 0.19.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.19.0\n",
            "Collecting pandas==0.20.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/6f/5733658857dffb998afa2120027171c263384ada0487a969e5ecd5bf9ac9/pandas-0.20.3-cp36-cp36m-manylinux1_x86_64.whl (24.5MB)\n",
            "\u001b[K     |████████████████████████████████| 24.5MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.20.3) (1.13.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.20.3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.20.3) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas==0.20.3) (1.15.0)\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.20.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.10.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.10.1 has requirement pandas>=0.22.0, but you'll have pandas 0.20.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.10.1 has requirement scipy>=1.0.1, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.20.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 0.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas-datareader 0.8.1 has requirement pandas>=0.21, but you'll have pandas 0.20.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.20.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.20.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: featuretools 0.4.1 has requirement numpy>=1.13.3, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: featuretools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.20.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.6 has requirement pandas>=0.23.4, but you'll have pandas 0.20.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 1.0.5\n",
            "    Uninstalling pandas-1.0.5:\n",
            "      Successfully uninstalled pandas-1.0.5\n",
            "Successfully installed pandas-0.20.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pjnkLHPYwcs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "edf156de-ab77-4984-fb6c-d9b0ac649779"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import sklearn\n",
        "import scipy.sparse \n",
        "\n",
        "for p in [np, pd, sklearn, scipy]:\n",
        "    print (p.__name__, p.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numpy 1.13.1\n",
            "pandas 0.20.3\n",
            "sklearn 0.19.0\n",
            "scipy 0.19.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXVVEYxiYwcz",
        "colab_type": "text"
      },
      "source": [
        "The versions should be not less than:\n",
        "\n",
        "    numpy 1.13.1\n",
        "    pandas 0.20.3\n",
        "    sklearn 0.19.0\n",
        "    scipy 0.19.1\n",
        "   \n",
        "**IMPORTANT!** The results with `scipy=1.0.0` will be different! Make sure you use _exactly_ version `0.19.1`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Scjja9dYwc0",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmRTv-z2Ywc1",
        "colab_type": "text"
      },
      "source": [
        "Learn features and labels. These features are actually OOF predictions of linear models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYvMs6mRaIpd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28d3e758-9154-447c-f026-f70b765d696c"
      },
      "source": [
        "! wget https://github.com/hse-aml/competitive-data-science/blob/master/readonly/KNN_features_data/X.npz?raw=true -O X.npz\n",
        "! wget https://github.com/hse-aml/competitive-data-science/blob/master/readonly/KNN_features_data/X_test.npz?raw=true -O X_test.npz\n",
        "! wget https://github.com/hse-aml/competitive-data-science/blob/master/readonly/KNN_features_data/Y.npy?raw=true -O Y.npy\n",
        "! wget https://github.com/hse-aml/competitive-data-science/blob/master/readonly/KNN_features_data/Y_test.npy?raw=true -O Y_test.npy\n",
        "! wget https://github.com/hse-aml/competitive-data-science/blob/master/readonly/KNN_features_data/knn_feats_test_first50.npy?raw=true -O knn_feats_test_first50.npy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-18 16:38:31--  https://github.com/hse-aml/competitive-data-science/blob/master/readonly/KNN_features_data/X.npz?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/hse-aml/competitive-data-science/raw/master/readonly/KNN_features_data/X.npz [following]\n",
            "--2020-08-18 16:38:31--  https://github.com/hse-aml/competitive-data-science/raw/master/readonly/KNN_features_data/X.npz\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/hse-aml/competitive-data-science/master/readonly/KNN_features_data/X.npz [following]\n",
            "--2020-08-18 16:38:31--  https://raw.githubusercontent.com/hse-aml/competitive-data-science/master/readonly/KNN_features_data/X.npz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2580919 (2.5M) [application/octet-stream]\n",
            "Saving to: ‘X.npz’\n",
            "\n",
            "X.npz               100%[===================>]   2.46M  9.75MB/s    in 0.3s    \n",
            "\n",
            "2020-08-18 16:38:32 (9.75 MB/s) - ‘X.npz’ saved [2580919/2580919]\n",
            "\n",
            "--2020-08-18 16:38:33--  https://github.com/hse-aml/competitive-data-science/blob/master/readonly/KNN_features_data/X_test.npz?raw=true\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/hse-aml/competitive-data-science/raw/master/readonly/KNN_features_data/X_test.npz [following]\n",
            "--2020-08-18 16:38:34--  https://github.com/hse-aml/competitive-data-science/raw/master/readonly/KNN_features_data/X_test.npz\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/hse-aml/competitive-data-science/master/readonly/KNN_features_data/X_test.npz [following]\n",
            "--2020-08-18 16:38:34--  https://raw.githubusercontent.com/hse-aml/competitive-data-science/master/readonly/KNN_features_data/X_test.npz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 288657 (282K) [application/octet-stream]\n",
            "Saving to: ‘X_test.npz’\n",
            "\n",
            "X_test.npz          100%[===================>] 281.89K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-08-18 16:38:34 (4.72 MB/s) - ‘X_test.npz’ saved [288657/288657]\n",
            "\n",
            "--2020-08-18 16:38:36--  https://github.com/hse-aml/competitive-data-science/blob/master/readonly/KNN_features_data/Y.npy?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/hse-aml/competitive-data-science/raw/master/readonly/KNN_features_data/Y.npy [following]\n",
            "--2020-08-18 16:38:36--  https://github.com/hse-aml/competitive-data-science/raw/master/readonly/KNN_features_data/Y.npy\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/hse-aml/competitive-data-science/master/readonly/KNN_features_data/Y.npy [following]\n",
            "--2020-08-18 16:38:36--  https://raw.githubusercontent.com/hse-aml/competitive-data-science/master/readonly/KNN_features_data/Y.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 402272 (393K) [application/octet-stream]\n",
            "Saving to: ‘Y.npy’\n",
            "\n",
            "Y.npy               100%[===================>] 392.84K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-08-18 16:38:36 (5.52 MB/s) - ‘Y.npy’ saved [402272/402272]\n",
            "\n",
            "--2020-08-18 16:38:37--  https://github.com/hse-aml/competitive-data-science/blob/master/readonly/KNN_features_data/Y_test.npy?raw=true\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/hse-aml/competitive-data-science/raw/master/readonly/KNN_features_data/Y_test.npy [following]\n",
            "--2020-08-18 16:38:38--  https://github.com/hse-aml/competitive-data-science/raw/master/readonly/KNN_features_data/Y_test.npy\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/hse-aml/competitive-data-science/master/readonly/KNN_features_data/Y_test.npy [following]\n",
            "--2020-08-18 16:38:38--  https://raw.githubusercontent.com/hse-aml/competitive-data-science/master/readonly/KNN_features_data/Y_test.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44768 (44K) [application/octet-stream]\n",
            "Saving to: ‘Y_test.npy’\n",
            "\n",
            "Y_test.npy          100%[===================>]  43.72K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-08-18 16:38:38 (1.73 MB/s) - ‘Y_test.npy’ saved [44768/44768]\n",
            "\n",
            "--2020-08-18 16:38:39--  https://github.com/hse-aml/competitive-data-science/blob/master/readonly/KNN_features_data/knn_feats_test_first50.npy?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/hse-aml/competitive-data-science/raw/master/readonly/KNN_features_data/knn_feats_test_first50.npy [following]\n",
            "--2020-08-18 16:38:39--  https://github.com/hse-aml/competitive-data-science/raw/master/readonly/KNN_features_data/knn_feats_test_first50.npy\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/hse-aml/competitive-data-science/master/readonly/KNN_features_data/knn_feats_test_first50.npy [following]\n",
            "--2020-08-18 16:38:39--  https://raw.githubusercontent.com/hse-aml/competitive-data-science/master/readonly/KNN_features_data/knn_feats_test_first50.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95680 (93K) [application/octet-stream]\n",
            "Saving to: ‘knn_feats_test_first50.npy’\n",
            "\n",
            "knn_feats_test_firs 100%[===================>]  93.44K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-08-18 16:38:40 (2.98 MB/s) - ‘knn_feats_test_first50.npy’ saved [95680/95680]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d26O-erTYwc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = 'X.npz'\n",
        "train_labels = 'Y.npy'\n",
        "\n",
        "test_path = 'X_test.npz'\n",
        "test_labels = 'Y_test.npy'\n",
        "\n",
        "# Train data\n",
        "X = scipy.sparse.load_npz(train_path)\n",
        "Y = np.load(train_labels)\n",
        "\n",
        "# Test data\n",
        "X_test = scipy.sparse.load_npz(test_path)\n",
        "Y_test = np.load(test_labels)\n",
        "\n",
        "# Out-of-fold features we loaded above were generated with n_splits=4 and skf seed 123\n",
        "# So it is better to use seed 123 for generating KNN features as well \n",
        "skf_seed = 123\n",
        "n_splits = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaHXJwZ4Ywc9",
        "colab_type": "text"
      },
      "source": [
        "Below you need to implement features, based on nearest neighbors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIpKLyViYwc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from multiprocessing import Pool\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class NearestNeighborsFeats(BaseEstimator, ClassifierMixin):\n",
        "    '''\n",
        "        This class should implement KNN features extraction \n",
        "    '''\n",
        "    def __init__(self, n_jobs, k_list, metric, n_classes=None, n_neighbors=None, eps=1e-6):\n",
        "        self.n_jobs = n_jobs\n",
        "        self.k_list = k_list\n",
        "        self.metric = metric\n",
        "        \n",
        "        if n_neighbors is None:\n",
        "            self.n_neighbors = max(k_list) \n",
        "        else:\n",
        "            self.n_neighbors = n_neighbors\n",
        "            \n",
        "        self.eps = eps        \n",
        "        self.n_classes_ = n_classes\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "            Set's up the train set and self.NN object\n",
        "        '''\n",
        "        # Create a NearestNeighbors (NN) object. We will use it in `predict` function \n",
        "        self.NN = NearestNeighbors(n_neighbors=max(self.k_list), \n",
        "                                      metric=self.metric, \n",
        "                                      n_jobs=1, \n",
        "                                      algorithm='brute' if self.metric=='cosine' else 'auto')\n",
        "        self.NN.fit(X)\n",
        "        \n",
        "        # Store labels \n",
        "        self.y_train = y\n",
        "        \n",
        "        # Save how many classes we have\n",
        "        self.n_classes = np.unique(y).shape[0] if self.n_classes_ is None else self.n_classes_\n",
        "        \n",
        "        \n",
        "    def predict(self, X):       \n",
        "        '''\n",
        "            Produces KNN features for every object of a dataset X\n",
        "        '''\n",
        "        if self.n_jobs == 1:\n",
        "            test_feats = []\n",
        "            for i in range(X.shape[0]):\n",
        "                test_feats.append(self.get_features_for_one(X[i:i+1]))\n",
        "        else:\n",
        "            '''\n",
        "                 *Make it parallel*\n",
        "                     Number of threads should be controlled by `self.n_jobs`  \n",
        "                     \n",
        "                     \n",
        "                     You can use whatever you want to do it\n",
        "                     For Python 3 the simplest option would be to use \n",
        "                     `multiprocessing.Pool` (but don't use `multiprocessing.dummy.Pool` here)\n",
        "                     You may try use `joblib` but you will most likely encounter an error, \n",
        "                     that you will need to google up (and eventually it will work slowly)\n",
        "                     \n",
        "                     For Python 2 I also suggest using `multiprocessing.Pool` \n",
        "                     You will need to use a hint from this blog \n",
        "                     http://qingkaikong.blogspot.ru/2016/12/python-parallel-method-in-class.html\n",
        "                     I could not get `joblib` working at all for this code \n",
        "                     (but in general `joblib` is very convenient)\n",
        "                     \n",
        "            '''\n",
        "            \n",
        "            # YOUR CODE GOES HERE\n",
        "            # test_feats =  # YOUR CODE GOES HERE\n",
        "            test_feats = Pool(self.n_jobs).map(self.get_features_for_one,\n",
        "                                              (X[i:i+1] for i in range(X.shape[0])))\n",
        "            # YOUR CODE GOES HERE\n",
        "            \n",
        "#             assert False, 'You need to implement it for n_jobs > 1'\n",
        "            \n",
        "            \n",
        "            \n",
        "        return np.vstack(test_feats)\n",
        "        \n",
        "        \n",
        "    def get_features_for_one(self, x):\n",
        "        '''\n",
        "            Computes KNN features for a single object `x`\n",
        "        '''\n",
        "\n",
        "        NN_output = self.NN.kneighbors(x)\n",
        "        \n",
        "        # Vector of size `n_neighbors`\n",
        "        # Stores indices of the neighbors\n",
        "        neighs = NN_output[1][0]\n",
        "        \n",
        "        # Vector of size `n_neighbors`\n",
        "        # Stores distances to corresponding neighbors\n",
        "        neighs_dist = NN_output[0][0] \n",
        "\n",
        "        # Vector of size `n_neighbors`\n",
        "        # Stores labels of corresponding neighbors\n",
        "        neighs_y = self.y_train[neighs] \n",
        "        \n",
        "        ## ========================================== ##\n",
        "        ##              YOUR CODE BELOW\n",
        "        ## ========================================== ##\n",
        "        \n",
        "        # We will accumulate the computed features here\n",
        "        # Eventually it will be a list of lists or np.arrays\n",
        "        # and we will use np.hstack to concatenate those\n",
        "        return_list = [] \n",
        "        \n",
        "        \n",
        "        ''' \n",
        "            1. Fraction of objects of every class.\n",
        "               It is basically a KNNСlassifiers predictions.\n",
        "\n",
        "               Take a look at `np.bincount` function, it can be very helpful\n",
        "               Note that the values should sum up to one\n",
        "        '''\n",
        "        for k in self.k_list:\n",
        "            # YOUR CODE GOES HERE\n",
        "            feats = np.bincount(neighs_y[:k], minlength=self.n_classes) / k\n",
        "            \n",
        "            assert len(feats) == self.n_classes\n",
        "            return_list += [feats]\n",
        "        \n",
        "        \n",
        "        '''\n",
        "            2. Same label streak: the largest number N, \n",
        "               such that N nearest neighbors have the same label.\n",
        "               \n",
        "               What can help you: `np.where`\n",
        "        '''\n",
        "        \n",
        "        feats = 1 + \\\n",
        "                np.where(np.append(neighs_y[:-1] != neighs_y[1:], True))[0].min(keepdims=True)# YOUR CODE GOES HERE\n",
        "        \n",
        "        assert len(feats) == 1\n",
        "        return_list += [feats]\n",
        "        \n",
        "        '''\n",
        "            3. Minimum distance to objects of each class\n",
        "               Find the first instance of a class and take its distance as features.\n",
        "               \n",
        "               If there are no neighboring objects of some classes, \n",
        "               Then set distance to that class to be 999.\n",
        "\n",
        "               `np.where` might be helpful\n",
        "        '''\n",
        "        feats = []\n",
        "        for c in range(self.n_classes):\n",
        "            feats.append(np.append(neighs_dist[neighs_y == c], 999).min())# YOUR CODE GOES HERE\n",
        "        \n",
        "        assert len(feats) == self.n_classes\n",
        "        return_list += [feats]\n",
        "        \n",
        "        '''\n",
        "            4. Minimum *normalized* distance to objects of each class\n",
        "               As 3. but we normalize (divide) the distances\n",
        "               by the distance to the closest neighbor.\n",
        "               \n",
        "               If there are no neighboring objects of some classes, \n",
        "               Then set distance to that class to be 999.\n",
        "               \n",
        "               Do not forget to add self.eps to denominator.\n",
        "        '''\n",
        "        feats = []\n",
        "        for c in range(self.n_classes):\n",
        "            # YOUR CODE GOES HERE\n",
        "            feat = neighs_dist[neighs_y == c] / (neighs_dist[0] + self.eps)\n",
        "            feats.append(feat.min() if feat.size else 999)\n",
        "        \n",
        "        assert len(feats) == self.n_classes\n",
        "        return_list += [feats]\n",
        "        \n",
        "        '''\n",
        "            5. \n",
        "               5.1 Distance to Kth neighbor\n",
        "                   Think of this as of quantiles of a distribution\n",
        "               5.2 Distance to Kth neighbor normalized by \n",
        "                   distance to the first neighbor\n",
        "               \n",
        "               feat_51, feat_52 are answers to 5.1. and 5.2.\n",
        "               should be scalars\n",
        "               \n",
        "               Do not forget to add self.eps to denominator.\n",
        "        '''\n",
        "        for k in self.k_list:\n",
        "            \n",
        "            feat_51 = neighs_dist[k-1] # YOUR CODE GOES HERE\n",
        "            feat_52 = neighs_dist[k-1] / (neighs_dist[0] + self.eps)# YOUR CODE GOES HERE\n",
        "            \n",
        "            return_list += [[feat_51, feat_52]]\n",
        "        \n",
        "        '''\n",
        "            6. Mean distance to neighbors of each class for each K from `k_list` \n",
        "                   For each class select the neighbors of that class among K nearest neighbors \n",
        "                   and compute the average distance to those objects\n",
        "                   \n",
        "                   If there are no objects of a certain class among K neighbors, set mean distance to 999\n",
        "                   \n",
        "               You can use `np.bincount` with appropriate weights\n",
        "               Don't forget, that if you divide by something, \n",
        "               You need to add `self.eps` to denominator.\n",
        "        '''\n",
        "        for k in self.k_list:\n",
        "            \n",
        "            # YOUR CODE GOES IN HERE\n",
        "            bincount = np.bincount(neighs_y[:k], minlength=self.n_classes)\n",
        "            feats = np.where(\n",
        "                bincount,\n",
        "                np.bincount(neighs_y[:k], weights=neighs_dist[:k], minlength=self.n_classes) / (bincount+self.eps),\n",
        "                999\n",
        "            )\n",
        "            \n",
        "            assert len(feats) == self.n_classes\n",
        "            return_list += [feats]\n",
        "        \n",
        "        \n",
        "        # merge\n",
        "        knn_feats = np.hstack(return_list)\n",
        "        \n",
        "        assert knn_feats.shape == (239,) or knn_feats.shape == (239, 1)\n",
        "        return knn_feats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6_Lfo7-YwdD",
        "colab_type": "text"
      },
      "source": [
        "## Sanity check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw3A8WneYwdE",
        "colab_type": "text"
      },
      "source": [
        "To make sure you've implemented everything correctly we provide you the correct features for the first 50 objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGmsX5BlYwdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d8d849d-7bf2-48a8-fcaa-06857c8373f6"
      },
      "source": [
        "# a list of K in KNN, starts with one \n",
        "k_list = [3, 8, 32]\n",
        "\n",
        "# Load correct features\n",
        "true_knn_feats_first50 = np.load('knn_feats_test_first50.npy')\n",
        "\n",
        "# Create instance of our KNN feature extractor\n",
        "NNF = NearestNeighborsFeats(n_jobs=1, k_list=k_list, metric='minkowski')\n",
        "\n",
        "# Fit on train set\n",
        "NNF.fit(X, Y)\n",
        "\n",
        "# Get features for test\n",
        "test_knn_feats = NNF.predict(X_test[:50])\n",
        "\n",
        "# This should be zero\n",
        "print ('Deviation from ground thruth features: %f' % np.abs(test_knn_feats - true_knn_feats_first50).sum())\n",
        "\n",
        "deviation =np.abs(test_knn_feats - true_knn_feats_first50).sum(0)\n",
        "for m in np.where(deviation > 1e-3)[0]: \n",
        "    p = np.where(np.array([87, 88, 117, 146, 152, 239]) > m)[0][0]\n",
        "    print ('There is a problem in feature %d, which is a part of section %d.' % (m, p + 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deviation from ground thruth features: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcllUgh3YwdM",
        "colab_type": "text"
      },
      "source": [
        "Now implement parallel computations and compute features for the train and test sets. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S9hAnQMYwdN",
        "colab_type": "text"
      },
      "source": [
        "## Get features for test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fmBz_TUYwdO",
        "colab_type": "text"
      },
      "source": [
        "Now compute features for the whole test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE_q1VFbYwdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e6597c83-a951-44ef-c4c6-19772c0b2bbe"
      },
      "source": [
        "%%time\n",
        "import os\n",
        "from tqdm import tqdm_notebook\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "for metric in (['minkowski', 'cosine']):\n",
        "    print (metric)\n",
        "    \n",
        "    # Create instance of our KNN feature extractor\n",
        "    NNF = NearestNeighborsFeats(n_jobs=cpu_count(), k_list=k_list, metric=metric)\n",
        "    \n",
        "    # Fit on train set\n",
        "    NNF.fit(X, Y)\n",
        "\n",
        "    # Get features for test\n",
        "    test_knn_feats = NNF.predict(X_test)\n",
        "    \n",
        "    # Dump the features to disk\n",
        "    np.save('knn_feats_%s_test.npy' % metric , test_knn_feats)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "minkowski\n",
            "cosine\n",
            "CPU times: user 1.62 s, sys: 421 ms, total: 2.04 s\n",
            "Wall time: 1min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRbpTlK4YwdU",
        "colab_type": "text"
      },
      "source": [
        "## Get features for train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlsvnjwCYwdV",
        "colab_type": "text"
      },
      "source": [
        "Compute features for train, using out-of-fold strategy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zj4zHitYwdY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "fffab9af-c0b2-4abc-ac78-24a5d5c4b03f"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Differently from other homework we will not implement OOF predictions ourselves\n",
        "# but use sklearn's `cross_val_predict`\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# We will use two metrics for KNN\n",
        "for metric in (['minkowski', 'cosine']):\n",
        "    print (metric)\n",
        "    \n",
        "    # Set up splitting scheme, use StratifiedKFold\n",
        "    # use skf_seed and n_splits defined above with shuffle=True\n",
        "    skf = StratifiedKFold(n_splits=n_splits,\n",
        "                          shuffle=True,\n",
        "                          random_state=skf_seed) # YOUR CODE GOES HERE\n",
        "    \n",
        "    # Create instance of our KNN feature extractor\n",
        "    # n_jobs can be larger than the number of cores\n",
        "    NNF = NearestNeighborsFeats(n_jobs=cpu_count(), k_list=k_list, metric=metric)\n",
        "    \n",
        "    # Get KNN features using OOF use cross_val_predict with right parameters\n",
        "    preds = cross_val_predict(NNF, X, y=Y, cv=skf) # YOUR CODE GOES HERE\n",
        "    \n",
        "    # Save the features\n",
        "    np.save('knn_feats_%s_train.npy' % metric, preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "minkowski\n",
            "cosine\n",
            "CPU times: user 14.8 s, sys: 4.32 s, total: 19.1 s\n",
            "Wall time: 9min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ASl2-DSYwdc",
        "colab_type": "text"
      },
      "source": [
        "# Submit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pRk6lAKYwdd",
        "colab_type": "text"
      },
      "source": [
        "If you made the above cells work, just run the following cell to produce a number to submit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ySoI-BIYwde",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "768588dd-e600-4b71-e06c-6a7755e841ab"
      },
      "source": [
        "s = 0\n",
        "for metric in ['minkowski', 'cosine']:\n",
        "    knn_feats_train = np.load('knn_feats_%s_train.npy' % metric)\n",
        "    knn_feats_test = np.load('knn_feats_%s_test.npy' % metric)\n",
        "    \n",
        "    s += knn_feats_train.mean() + knn_feats_test.mean()\n",
        "    \n",
        "answer = np.floor(s)\n",
        "print (answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3838.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypawaqVHYwdj",
        "colab_type": "text"
      },
      "source": [
        "Submit!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiRhoI-bYwdk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "bf10c30d-d366-4514-a89b-02bb88dd44b8"
      },
      "source": [
        "from grader import Grader\n",
        "\n",
        "grader = Grader()\n",
        "\n",
        "grader.submit_tag('statistic', answer)\n",
        "\n",
        "STUDENT_EMAIL = \"ebube.madu.243204@unn.edu.ng\"\n",
        "STUDENT_TOKEN = \"y7tXLhXmO4a2RIMH\"\n",
        "grader.status()\n",
        "\n",
        "grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current answer for task statistic is: 3838.0\n",
            "You want to submit these numbers:\n",
            "Task statistic: 3838.0\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8jPC2vece6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}